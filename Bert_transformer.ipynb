{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b564dd-e244-4518-8a95-bbc90b9a6747",
   "metadata": {},
   "source": [
    "# 安裝 & 設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71364931-f908-4324-a2de-d3adbabfd6b4",
   "metadata": {},
   "source": [
    "## 下載Bert的中文模型"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1350e04a-5fc8-4663-acdf-c4482fc30135",
   "metadata": {},
   "source": [
    "wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip -p ~/Projects/TSGH2021-AI/\n",
    "unzip chinese_L-12_H-768_A-12.zip -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4ee58-9c53-4f28-8c57-85489b9069c9",
   "metadata": {},
   "source": [
    "## 安裝繁簡轉換工具"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7de05421-6d43-4598-aa34-63e769a32b61",
   "metadata": {},
   "source": [
    "pip install opencc-python-reimplemented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f4083-4c50-4f9f-a917-cc642eba1f91",
   "metadata": {},
   "source": [
    "## 測試繁簡轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5746bb48-9ea6-4ebf-958d-2697e40edcf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'上海2010上半年四六級考試報名4月8日前完成'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opencc import OpenCC\n",
    "cc = OpenCC('s2t')\n",
    "cc.convert('上海2010上半年四六级考试报名4月8日前完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e62267-4864-4954-abe2-58786e9fdb20",
   "metadata": {},
   "source": [
    "# 建立 BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7785f3-e2b1-46ea-b48e-a7660fcf12f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-29 17:01:35.484755: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-29 17:01:35.484795: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ebdb01-1218-4c76-aa8c-2a64cb0d28ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb97a62-5588-4979-a00e-3357dc824c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['它',\n",
       " '的',\n",
       " '特',\n",
       " '性',\n",
       " '是',\n",
       " '難',\n",
       " '以',\n",
       " '專',\n",
       " '注',\n",
       " '、',\n",
       " '過',\n",
       " '度',\n",
       " '活',\n",
       " '躍',\n",
       " '、',\n",
       " '做',\n",
       " '事',\n",
       " '不',\n",
       " '考',\n",
       " '慮',\n",
       " '後',\n",
       " '果',\n",
       " '等',\n",
       " '等',\n",
       " '。',\n",
       " '除',\n",
       " '此',\n",
       " '之',\n",
       " '外',\n",
       " '，',\n",
       " '還',\n",
       " '有',\n",
       " '不',\n",
       " '合',\n",
       " '年',\n",
       " '紀',\n",
       " '的',\n",
       " '行',\n",
       " '為']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"它的特性是難以專注、過度活躍、做事不考慮後果等等。除此之外，還有不合年紀的行為\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaee5bcf-195f-457e-9c62-c1f28df7561d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2124,\n",
       " 4638,\n",
       " 4294,\n",
       " 2595,\n",
       " 3221,\n",
       " 7432,\n",
       " 809,\n",
       " 2201,\n",
       " 3800,\n",
       " 510,\n",
       " 6882,\n",
       " 2428,\n",
       " 3833,\n",
       " 6713,\n",
       " 510,\n",
       " 976,\n",
       " 752,\n",
       " 679,\n",
       " 5440,\n",
       " 2719,\n",
       " 2527,\n",
       " 3362,\n",
       " 5023,\n",
       " 5023,\n",
       " 511,\n",
       " 7370,\n",
       " 3634,\n",
       " 722,\n",
       " 1912,\n",
       " 8024,\n",
       " 6917,\n",
       " 3300,\n",
       " 679,\n",
       " 1394,\n",
       " 2399,\n",
       " 5145,\n",
       " 4638,\n",
       " 6121,\n",
       " 4158]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"它的特性是難以專注、過度活躍、做事不考慮後果等等。除此之外，還有不合年紀的行為\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee457c3-e963-4a67-9fb0-9b8c83a55661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text_input:str): # 自動轉換繁體之後轉成ID\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(cc.convert(text_input)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461900d8-4541-4c55-bd51-60f7d276a489",
   "metadata": {},
   "source": [
    "# 讀取Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2275b57f-8fd2-4bc6-8d4e-6acaeb4a37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c0edcc-a23c-4f09-83ba-5eaceddeaa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gunpow777/.nchc_conda/envs/jupyterlab/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('toutiao_cat_data.txt',sep='_!_',header=None,names=['1','2','label','text','3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7433b165-dc1b-494e-a5c0-9d95b6643549",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_raw[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9969008a-d22b-4834-ba18-e308848e8662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29aa55ee-514a-49f4-b1cc-47d47a214c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382688, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c78d8ed-f39c-4d11-9146-711701508fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(10000)\n",
    "text = dataset['text'].values\n",
    "label = dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71955589-87b9-4159-bdf3-d80c2ab5cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2935a23-986c-4589-877c-cb4674f53b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0234a8e-dd07-4e4d-ae91-ebb9010ad576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bace53b0-5c0e-465b-b184-3401f2e551a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1e38ed8-19e0-4748-b526-7c01c4af83c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'索天科技2017年营收7519万元 净赚1363万元'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0388903-7fc0-4767-be45-dfe163986cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5164,\n",
       " 1921,\n",
       " 4906,\n",
       " 2825,\n",
       " 8109,\n",
       " 2399,\n",
       " 4245,\n",
       " 3119,\n",
       " 8273,\n",
       " 8818,\n",
       " 5857,\n",
       " 1039,\n",
       " 3912,\n",
       " 6553,\n",
       " 9015,\n",
       " 8152,\n",
       " 5857,\n",
       " 1039]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_text(text[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5717e7e7-570f-4e7f-9379-c9118c25ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'news_finance'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5a48c91-ee95-4418-b0c0-571fb9bc1697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15b53b-2bfa-4955-9861-d02539e46dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba5d73d-0a2a-4816-a9b9-33562a1b9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [tokenize_text(i) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1813020c-40ea-42da-b11e-80d1a77e6432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a277262-9f1c-48a8-9167-be56d45a04cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label_len = [[text,y[i],len(text)] for i, text in enumerate(tokenized_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52907fce-ee34-46a5-a785-a201e64a2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_label_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f0addee-a11b-4b6c-8f69-fded82f6306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_label_len.sort(key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c099c9-29c8-482f-a7f9-995ff7bbc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_text_label = [(comps[0],comps[1]) for comps in text_label_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6a510-4ea2-458b-a95f-5b61a7fcb55d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdecf9ae-c5ea-44b5-a685-2fd7d39a9a7e",
   "metadata": {},
   "source": [
    "# 建立TFDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "175c9b64-200b-403c-bcd0-565e0aa9bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_label, output_types=(tf.int32, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6f492a8-286f-4867-b18e-e084ee85702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "max_len = 32\n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((max_len, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83be4acd-d987-41a4-8534-e847f6160c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128, 32), dtype=int32, numpy=\n",
       " array([[2961, 7030,  100, ...,    0,    0,    0],\n",
       "        [5847, 6965, 2119, ...,    0,    0,    0],\n",
       "        [3984, 2336, 1920, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [3582, 1690,  782, ...,    0,    0,    0],\n",
       "        [6306, 5543, 2802, ...,    0,    0,    0],\n",
       "        [1066, 4089, 1927, ...,    0,    0,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(128,), dtype=int32, numpy=\n",
       " array([ 1,  3,  3,  9,  2,  2, 12,  5, 13, 11,  2,  2,  3, 12,  2,  6, 12,\n",
       "         2,  2, 12,  3,  1, 13, 11, 12,  1, 12,  5, 11,  1, 10,  3,  5, 12,\n",
       "         8,  0,  6,  5,  3, 12,  2,  0,  8,  9,  2, 11,  7,  7,  3,  8,  2,\n",
       "         8, 11,  8,  3, 13, 13,  3,  0,  2,  2,  1, 13,  3, 13, 12,  0,  4,\n",
       "        11, 13,  3, 12,  3, 13,  0,  0,  6, 13,  0,  3,  1, 11,  1, 12, 11,\n",
       "         3,  1, 12,  0,  0, 11,  0,  3, 11, 11, 11,  9,  2,  2,  5,  2,  2,\n",
       "         2,  6,  4,  3, 11, 11,  1, 11,  8,  2,  2, 12,  5,  3, 11,  8,  5,\n",
       "         3, 11, 13,  4, 11, 11, 11,  9, 12], dtype=int32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d53959-2e96-42f9-b01d-f8678c2edc1e",
   "metadata": {},
   "source": [
    "## 製作訓練測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00e27261-4ed6-472a-abde-78a20aec2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "TOTAL_BATCHES = math.ceil(len(sorted_text_label) / BATCH_SIZE)\n",
    "TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d36c4ec9-8949-4b4d-a4f4-6bcf98a52593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42a2c31f-3240-4538-ad87-b92b1620dadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f2b1fae-1bd3-4261-9de3-2d319bc5e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0284a-83c7-4313-a25b-ec14431a8aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "      1/Unknown - 47s 47s/step - loss: 55.3801 - accuracy: 0.0547"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aee9e7-892f-4f6d-954a-66989aa993ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e66ec0-4cb1-4520-9d43-e49694dff5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
